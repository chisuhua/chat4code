"""
chat4code æ ¸å¿ƒæ¨¡å—
"""

import os
import json
import hashlib
import re
from datetime import datetime
from typing import List, Tuple, Dict, Optional, Set
from .tasks import TaskManager
from .parser import ResponseParser
from .validator import ResponseValidator
from .config import ConfigManager
import fnmatch
import glob

class CodeProjectAIHelper:
    def __init__(self):
        # åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
        self.config_manager = ConfigManager()
        
        # ä»é…ç½®è·å–è®¾ç½®
        self.language_map = self.config_manager.get_language_map()
        self.default_extensions = self.config_manager.get_extensions()
        self.metadata_dir = self.config_manager.get_metadata_dir()
        self.exclude_patterns = self.config_manager.get_exclude_patterns()
        
        # åˆå§‹åŒ–å­æ¨¡å—ï¼ˆä¼ é€’é…ç½®ä¸­çš„æç¤ºè¯æ–‡ä»¶è·¯å¾„ï¼‰
        prompts_file = self.config_manager.get("prompts_file", None)
        try:
            self.task_manager = TaskManager(prompts_file)
        except FileNotFoundError as e:
            print(f"âŒ {e}")
            print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
            print("   1. è¿è¡Œ 'python -m chat4code --config-init' åˆå§‹åŒ–é…ç½®")
            print("   2. æˆ–è€…æ‰‹åŠ¨åˆ›å»º prompts.yaml æ–‡ä»¶")
            print("   3. æˆ–è€…åœ¨ .chat4code.json ä¸­æŒ‡å®š prompts_file è·¯å¾„")
            raise
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–ä»»åŠ¡ç®¡ç†å™¨å¤±è´¥: {e}")
            raise
            
        self.response_parser = ResponseParser()
        self.response_validator = ResponseValidator()

    def get_next_sequential_filename(self, pattern: str, output_dir: str) -> str:
        """
        è·å–ä¸‹ä¸€ä¸ªåºåˆ—åŒ–æ–‡ä»¶å
        ä¾‹å¦‚: req.md -> req1.md, req2.md, req3.md...
        """
        # åˆ†ç¦»æ–‡ä»¶åå’Œæ‰©å±•å
        base_name, ext = os.path.splitext(pattern)
        
        # è·å–ç›®å½•ä¸­å·²æœ‰çš„æ–‡ä»¶
        existing_files = []
        if os.path.exists(output_dir):
            for file in os.listdir(output_dir):
                if file.startswith(base_name) and file.endswith(ext):
                    existing_files.append(file)
        
        # æ‰¾åˆ°æœ€å¤§çš„åºåˆ—å·
        max_num = 0
        for file in existing_files:
            # åŒ¹é… req1.md, req2.md è¿™æ ·çš„æ¨¡å¼
            match = re.match(rf'{re.escape(base_name)}(\d+){re.escape(ext)}', file)
            if match:
                num = int(match.group(1))
                max_num = max(max_num, num)
        
        # ç”Ÿæˆä¸‹ä¸€ä¸ªåºåˆ—å·
        next_num = max_num + 1
        new_filename = f"{base_name}{next_num}{ext}"
        return os.path.join(output_dir, new_filename)

    def _match_source_dirs(self, src_dirs: List[str], base_dir: str = ".") -> List[str]:
        """
        æ ¹æ®æ¨¡å¼åŒ¹é…æºç›®å½•
        æ”¯æŒé€šé…ç¬¦å¦‚ 'ex*' åŒ¹é… ex å¼€å¤´çš„ç›®å½•
        """
        matched_dirs = []
        if not src_dirs:
            return [base_dir]
            
        for src_dir in src_dirs:
            # å¦‚æœæ˜¯ç»å¯¹è·¯å¾„æˆ–å·²åŒ…å«è·¯å¾„åˆ†éš”ç¬¦ï¼Œåˆ™ç›´æ¥ä½¿ç”¨
            if os.path.isabs(src_dir) or os.sep in src_dir or (os.altsep and os.altsep in src_dir):
                if os.path.exists(src_dir):
                    matched_dirs.append(src_dir)
                else:
                    print(f"âš ï¸ æŒ‡å®šçš„æºç›®å½•ä¸å­˜åœ¨: {src_dir}")
            else:
                # åœ¨ base_dir ä¸‹æŸ¥æ‰¾åŒ¹é…çš„ç›®å½•
                search_path = os.path.join(base_dir, src_dir)
                if '*' in src_dir or '?' in src_dir:
                    # ä½¿ç”¨ glob åŒ¹é…
                    matches = glob.glob(search_path)
                    for match in matches:
                        if os.path.isdir(match):
                            matched_dirs.append(match)
                else:
                    # ç›´æ¥æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
                    if os.path.exists(search_path) and os.path.isdir(search_path):
                        matched_dirs.append(search_path)
                    else:
                        print(f"âš ï¸ æŒ‡å®šçš„æºç›®å½•ä¸å­˜åœ¨: {search_path}")
        
        if not matched_dirs:
            print("âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„æºç›®å½•ï¼Œä½¿ç”¨é»˜è®¤ç›®å½•")
            matched_dirs = [base_dir]
            
        return matched_dirs

    def export_to_markdown(self, src_dirs: List[str] = None, output_file: str = None, 
                          extensions: tuple = None, task: str = None,
                          incremental: bool = False, since_time: str = None,
                          include_task_prompt: bool = False) -> str:
        """
        å¯¼å‡ºä»£ç åˆ°Markdownï¼Œæ”¯æŒå¢é‡å¯¼å‡ºå’Œæ™ºèƒ½ä»»åŠ¡æç¤º
        é»˜è®¤ä»»åŠ¡æç¤ºæ˜¾ç¤ºåœ¨å±å¹•ä¸Šï¼Œä½¿ç”¨ --task-prompt æ—¶åŒ…å«åœ¨å¯¼å‡ºæ–‡ä»¶ä¸­
        æ”¯æŒå¤šä¸ªæºç›®å½•å’Œæ¨¡å¼åŒ¹é…
        """
        # ä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤å€¼
        if src_dirs is None:
            src_dirs = self.config_manager.get_default_source_dirs()
        
        # åŒ¹é…æºç›®å½•
        matched_src_dirs = self._match_source_dirs(src_dirs)
        
        if extensions is None:
            extensions = self.default_extensions
            
        # æ£€æŸ¥æ‰€æœ‰æºç›®å½•æ˜¯å¦å­˜åœ¨
        for src_dir in matched_src_dirs:
            if not os.path.exists(src_dir):
                raise FileNotFoundError(f"æºç›®å½•ä¸å­˜åœ¨: {src_dir}")
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºæ–‡ä»¶ï¼Œä½¿ç”¨åºåˆ—åŒ–æ–‡ä»¶å
        if output_file is None:
            export_pattern = self.config_manager.get_export_filename_pattern()
            export_dir = self.config_manager.get_export_output_dir()
            output_file = self.get_next_sequential_filename(export_pattern, export_dir)
            print(f"â„¹ï¸  ä½¿ç”¨è‡ªåŠ¨åºåˆ—åŒ–æ–‡ä»¶å: {output_file}")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = os.path.dirname(output_file)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir)
         
        # æ£€æµ‹é¡¹ç›®ç±»å‹ï¼ˆæ”¯æŒé…ç½®å¼ºåˆ¶æŒ‡å®šï¼‰
        project_type = self._detect_project_type_multi(matched_src_dirs, extensions)
        
        # å¦‚æœæ˜¯å¢é‡å¯¼å‡ºï¼Œè·å–å˜æ›´çš„æ–‡ä»¶
        changed_files = None
        if incremental:
            changed_files = self._get_changed_files_multi(matched_src_dirs, since_time)
        
        markdown_lines = []
        
        # æ·»åŠ æ ‡é¢˜å’ŒåŸºæœ¬ä¿¡æ¯
        markdown_lines.append("# é¡¹ç›®ä»£ç å¯¼å‡º")
        markdown_lines.append(f"é¡¹ç›®åç§°: {', '.join([os.path.basename(os.path.abspath(src_dir)) for src_dir in matched_src_dirs])}")
        markdown_lines.append(f"å¯¼å‡ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        markdown_lines.append(f"æºç›®å½•: {', '.join([os.path.abspath(src_dir) for src_dir in matched_src_dirs])}")
        markdown_lines.append(f"é¡¹ç›®ç±»å‹: {project_type}")
        if self.config_manager.get_project_type():
            markdown_lines.append("ç±»å‹æ¥æº: é…ç½®æŒ‡å®š")
        else:
            markdown_lines.append("ç±»å‹æ¥æº: è‡ªåŠ¨æ£€æµ‹")
        if incremental:
            markdown_lines.append("æ¨¡å¼: å¢é‡å¯¼å‡º")
            if since_time:
                markdown_lines.append(f"è‡ªæ—¶é—´: {since_time}")
            else:
                markdown_lines.append("è‡ªä¸Šæ¬¡å¯¼å‡ºä»¥æ¥çš„å˜æ›´")
        markdown_lines.append(" ")
        markdown_lines.append("---")
        markdown_lines.append(" ")
        
        # å¦‚æœæœ‰ä»»åŠ¡ï¼Œå¤„ç†ä»»åŠ¡æç¤º
        task_info = None
        if task and self.task_manager.has_task(task):
            task_info = self.task_manager.get_task_info(task, project_type)
            if include_task_prompt:
                # åœ¨å¯¼å‡ºæ–‡ä»¶ä¸­åŒ…å«ä»»åŠ¡æç¤º
                markdown_lines.append("## AIä»»åŠ¡æç¤º")
                markdown_lines.append(" ")
                markdown_lines.append("**è¯·æŒ‰ç…§ä»¥ä¸‹è¦æ±‚æ‰§è¡Œä»»åŠ¡**: ")
                markdown_lines.append(task_info['prompt'])
                markdown_lines.append(" ")
                markdown_lines.append("---")
                markdown_lines.append(" ")
            else:
                # åªåœ¨å±å¹•ä¸Šæ˜¾ç¤ºä»»åŠ¡æç¤ºï¼Œä¸åœ¨å¯¼å‡ºæ–‡ä»¶ä¸­åŒ…å«
                print("\n=== AIä»»åŠ¡æç¤º ===")
                print("è¯·æŒ‰ç…§ä»¥ä¸‹è¦æ±‚æ‰§è¡Œä»»åŠ¡: ")
                print(task_info['prompt'])
                print("==================\n")
        
        # éå†æ‰€æœ‰åŒ¹é…çš„ç›®å½•
        file_count = 0
        for src_dir in matched_src_dirs:
            for root, _, files in os.walk(src_dir):
                for file in files:
                    if file.endswith(extensions):
                        file_path = os.path.join(root, file)
                        rel_path = os.path.relpath(file_path, src_dir)
                        
                        # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤æ­¤æ–‡ä»¶
                        if self._should_exclude_file(rel_path, self.exclude_patterns):
                            continue
                        
                        # å¦‚æœæ˜¯å¢é‡å¯¼å‡ºï¼Œåªå¤„ç†å˜æ›´çš„æ–‡ä»¶
                        if incremental and changed_files is not None:
                            if rel_path not in changed_files:
                                continue
                        
                        # æ·»åŠ æ–‡ä»¶æ ‡é¢˜
                        markdown_lines.append(f"## {rel_path}")
                        markdown_lines.append(" ")
                        
                        # ç¡®å®šä»£ç è¯­è¨€
                        lang = self._get_language_by_extension(file)
                        markdown_lines.append(f"```{lang}")
                        
                        # è¯»å–æ–‡ä»¶å†…å®¹
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                content = f.read()
                            markdown_lines.append(content)
                        except UnicodeDecodeError:
                            markdown_lines.append("[è¯¥æ–‡ä»¶æ— æ³•è¯»å–ï¼Œè¯·æ£€æŸ¥ç¼–ç æˆ–æ–‡ä»¶ç±»å‹]")
                        except Exception as e:
                            markdown_lines.append(f"[è¯»å–æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}]")
                        
                        markdown_lines.append("```")
                        markdown_lines.append(" ")
                        file_count += 1
        
        if file_count == 0:
            markdown_lines.append("## æœªæ‰¾åˆ°åŒ¹é…çš„ä»£ç æ–‡ä»¶")
            if incremental:
                markdown_lines.append("è‡ªä¸Šæ¬¡å¯¼å‡ºä»¥æ¥æ²¡æœ‰æ–‡ä»¶å˜æ›´")
            markdown_lines.append(f"è¯·æ£€æŸ¥ç›®å½•è·¯å¾„å’Œæ–‡ä»¶æ‰©å±•å: {', '.join(extensions)}")
            markdown_lines.append(" ")
        
        markdown_content = "\n".join(markdown_lines)
        
        # å¦‚æœæŒ‡å®šäº†è¾“å‡ºæ–‡ä»¶ï¼Œåˆ™ä¿å­˜ï¼›å¦åˆ™æ‰“å°åˆ°æ§åˆ¶å°
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(markdown_content)
            print(f"âœ… é¡¹ç›®å·²å¯¼å‡ºåˆ°: {output_file}")
            print(f"ğŸ“ åŒ…å« {file_count} ä¸ªä»£ç æ–‡ä»¶")
            
            # ä¿å­˜å¯¼å‡ºå…ƒæ•°æ®ï¼ˆç”¨äºå¢é‡å¯¼å‡ºï¼‰
            if not incremental:
                self._save_export_metadata_multi(matched_src_dirs, output_file)
        else:
            # è¾“å‡ºåˆ°æ§åˆ¶å°
            print(markdown_content)
        
        return output_file

    def apply_markdown_response(self, markdown_file: str = None, dst_dir: str = None, 
                                create_backup: bool = None, 
                                flexible_parsing: bool = True,
                                show_diff: bool = False) -> Dict:
        """
        åº”ç”¨Markdownå“åº”åˆ°æœ¬åœ°ç›®å½•ï¼Œæ”¯æŒå·®å¼‚æ˜¾ç¤º
        """
        # ä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤å€¼
        if markdown_file is None:
            import_pattern = self.config_manager.get_import_filename_pattern()
            import_dir = self.config_manager.get_import_output_dir()
            markdown_file = self.get_next_sequential_filename(import_pattern, import_dir)
            print(f"â„¹ï¸  ä½¿ç”¨è‡ªåŠ¨åºåˆ—åŒ–å¯¼å…¥æ–‡ä»¶: {markdown_file}")
        
        if dst_dir is None:
            dst_dir = self.config_manager.get_default_target_dir()
        
        # å¦‚æœæœªæŒ‡å®šå¤‡ä»½é€‰é¡¹ï¼Œä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤å€¼
        if create_backup is None:
            create_backup = self.config_manager.is_backup_enabled()
            
        if not os.path.exists(dst_dir):
            os.makedirs(dst_dir)
        
        # è¯»å–Markdownæ–‡ä»¶
        try:
            with open(markdown_file, 'r', encoding='utf-8') as f:
                markdown_content = f.read()
        except Exception as e:
            raise Exception(f"è¯»å–Markdownæ–‡ä»¶å¤±è´¥: {e}")
        
        # æå–æ–‡ä»¶ä¿¡æ¯
        if flexible_parsing:
            files = self.response_parser.extract_files_flexible(markdown_content)
        else:
            files = self.response_parser.extract_files_standard(markdown_content)
        
        result = {
            'success': [],
            'failed': [],
            'total': len(files),
            'parsed_files': [f[0] for f in files],
            'diffs': []  # ç”¨äºå­˜å‚¨å·®å¼‚ä¿¡æ¯
        }
        
        for file_path, lang, content in files:
            try:
                # æ£€æŸ¥æ˜¯å¦ä¸ºåˆ é™¤æ“ä½œ
                if lang == 'deleted' or content == 'DELETED':
                    # åˆ é™¤æ–‡ä»¶æ“ä½œ
                    full_path = os.path.join(dst_dir, file_path)
                    if os.path.exists(full_path):
                        if create_backup:
                            backup_path = f"{full_path}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                            os.rename(full_path, backup_path)
                            print(f"ğŸ—‘ï¸  åˆ é™¤æ–‡ä»¶ (å·²å¤‡ä»½): {full_path}")
                            result['deleted'].append({
                                'file': full_path,
                                'backup': backup_path
                            })
                        else:
                            os.remove(full_path)
                            print(f"ğŸ—‘ï¸  åˆ é™¤æ–‡ä»¶: {full_path}")
                            result['deleted'].append({
                                'file': full_path,
                                'backup': None
                            })
                    else:
                        print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•åˆ é™¤: {full_path}")
                        result['failed'].append({
                            'file': file_path,
                            'error': 'æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•åˆ é™¤'
                        })
                    continue

                # æ„å»ºå®Œæ•´è·¯å¾„
                full_path = os.path.join(dst_dir, file_path)
                
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤æ­¤æ–‡ä»¶
                if self._should_exclude_file(file_path, self.exclude_patterns):
                    print(f"âš ï¸  è·³è¿‡æ’é™¤çš„æ–‡ä»¶: {file_path}")
                    continue
                
                # å¦‚æœéœ€è¦æ˜¾ç¤ºå·®å¼‚ï¼Œè®¡ç®—å·®å¼‚
                diff_info = None
                if show_diff and os.path.exists(full_path):
                    diff_info = self._calculate_diff(full_path, content)
                
                # åˆ›å»ºç›®å½•
                file_dir = os.path.dirname(full_path)
                if file_dir and not os.path.exists(file_dir):
                    os.makedirs(file_dir)
                
                # åˆ›å»ºå¤‡ä»½ï¼ˆå¦‚æœæ–‡ä»¶å·²å­˜åœ¨ä¸”éœ€è¦å¤‡ä»½ï¼‰
                backup_path = None
                if create_backup and os.path.exists(full_path):
                    backup_path = f"{full_path}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    os.rename(full_path, backup_path)
                
                # å†™å…¥æ–‡ä»¶
                with open(full_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                success_info = {
                    'file': full_path,
                    'language': lang,
                    'backup': backup_path
                }
                
                if diff_info:
                    success_info['diff'] = diff_info
                    result['diffs'].append({
                        'file': full_path,
                        'diff': diff_info
                    })
                
                result['success'].append(success_info)
                print(f"âœ… åˆ›å»º/æ›´æ–°æ–‡ä»¶: {full_path}")
                
                # æ˜¾ç¤ºå·®å¼‚ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if show_diff and diff_info:
                    print(f"   å·®å¼‚ä¿¡æ¯: {diff_info['summary']}")
                
            except Exception as e:
                result['failed'].append({
                    'file': file_path,
                    'error': str(e)
                })
                print(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“Š å¤„ç†å®Œæˆ: {len(result['success'])}/{result['total']} ä¸ªæ–‡ä»¶æˆåŠŸ")
        if result['failed']:
            print("âŒ å¤±è´¥çš„æ–‡ä»¶: ")
            for item in result['failed']:
                print(f"   - {item['file']}: {item['error']}")
        
        # æ˜¾ç¤ºè¯¦ç»†å·®å¼‚æŠ¥å‘Š
        if show_diff and (result['diffs'] or result['deleted']):
            print("\nğŸ“ å·®å¼‚è¯¦æƒ…: ")
            print("= " * 50)
            for diff_info in result['diffs']:
                print(f"\næ–‡ä»¶: {diff_info['file']}")
                print(f"å·®å¼‚: {diff_info['diff']['summary']}")
                if diff_info['diff']['lines_added'] > 0:
                    print(f"      + æ–°å¢ {diff_info['diff']['lines_added']} è¡Œ")
                if diff_info['diff']['lines_removed'] > 0:
                    print(f"      - åˆ é™¤ {diff_info['diff']['lines_removed']} è¡Œ")
                if diff_info['diff']['lines_modified'] > 0:
                    print(f"      ~ ä¿®æ”¹ {diff_info['diff']['lines_modified']} è¡Œ")

            # æ˜¾ç¤ºåˆ é™¤çš„æ–‡ä»¶
            if 'deleted' in result and result['deleted']:
                print(f"\nğŸ—‘ï¸  åˆ é™¤çš„æ–‡ä»¶: ")
                for deleted_info in result['deleted']:
                    print(f"   - {deleted_info['file']}")
                    if deleted_info['backup']:
                        print(f"     (å·²å¤‡ä»½: {deleted_info['backup']})")
        
        return result

    def _should_exclude_file(self, file_path: str, exclude_patterns: List[str]) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åº”è¯¥è¢«æ’é™¤"""
        for pattern in exclude_patterns:
            if fnmatch.fnmatch(file_path, pattern):
                return True
            # ä¹Ÿæ£€æŸ¥ç›®å½•æ¨¡å¼
            if pattern.endswith('/') and file_path.startswith(pattern):
                return True
        return False

    def _detect_project_type_multi(self, src_dirs: List[str], extensions: tuple = None) -> str:
        """
        æ£€æµ‹å¤šä¸ªç›®å½•çš„é¡¹ç›®ç±»å‹ï¼ˆC++ã€Pythonã€JavaScriptç­‰ï¼‰
        å¦‚æœé…ç½®ä¸­æŒ‡å®šäº†é¡¹ç›®ç±»å‹ï¼Œåˆ™ä½¿ç”¨é…ç½®çš„ç±»å‹
        """
        # é¦–å…ˆæ£€æŸ¥é…ç½®ä¸­æ˜¯å¦å¼ºåˆ¶æŒ‡å®šäº†é¡¹ç›®ç±»å‹
        config_project_type = self.config_manager.get_project_type()
        if config_project_type:
            print(f"â„¹ï¸  ä½¿ç”¨é…ç½®æŒ‡å®šçš„é¡¹ç›®ç±»å‹: {config_project_type}")
            return config_project_type
        
        # å¦åˆ™è‡ªåŠ¨æ£€æµ‹é¡¹ç›®ç±»å‹ï¼ˆåŸºäºæ–‡ä»¶æ•°é‡ï¼‰
        if extensions is None:
            extensions = self.default_extensions
        
        # ç»Ÿè®¡å„ç±»å‹æ–‡ä»¶æ•°é‡
        cpp_extensions = {'.cpp', '.cc', '.cxx', '.c', '.h', '.hh', '.hpp'}
        python_extensions = {'.py'}
        js_extensions = {'.js', '.ts', '.jsx', '.tsx'}
         
        cpp_count = 0
        python_count = 0
        js_count = 0
        
        for src_dir in src_dirs:
            for root, _, files in os.walk(src_dir):
                for file in files:
                    if file.endswith(extensions):
                        _, ext = os.path.splitext(file.lower())
                        if ext in cpp_extensions:
                            cpp_count += 1
                        elif ext in python_extensions:
                            python_count += 1
                        elif ext in js_extensions:
                            js_count += 1
        
        print(f"ğŸ” é¡¹ç›®ç±»å‹æ£€æµ‹ç»“æœ: ")
        print(f"   C++ æ–‡ä»¶: {cpp_count} ä¸ª")
        print(f"   Python æ–‡ä»¶: {python_count} ä¸ª")
        print(f"   JavaScript æ–‡ä»¶: {js_count} ä¸ª")
        
        # æ ¹æ®æ–‡ä»¶æ•°é‡æœ€å¤šçš„ç±»å‹æ¥åˆ¤æ–­
        if cpp_count > python_count and cpp_count > js_count:
            detected_type = "cpp"
        elif python_count > cpp_count and python_count > js_count:
            detected_type = "python"
        elif js_count > cpp_count and js_count > python_count:
            detected_type = "javascript"
        else:
            detected_type = "generic"
        
        print(f"   æ£€æµ‹åˆ°é¡¹ç›®ç±»å‹: {detected_type}")
        return detected_type

    def _get_changed_files_multi(self, src_dirs: List[str], since_time: str = None) -> Set[str]:
        """
        è·å–å¤šä¸ªç›®å½•ä¸­å˜æ›´çš„æ–‡ä»¶åˆ—è¡¨
        """
        changed_files = set()
        
        for src_dir in src_dirs:
            changed_in_dir = self._get_changed_files(src_dir, since_time)
            changed_files.update(changed_in_dir)
            
        return changed_files

    def _get_changed_files(self, src_dir: str, since_time: str = None) -> set:
        """
        è·å–å˜æ›´çš„æ–‡ä»¶åˆ—è¡¨
        """
        changed_files = set()
        
        # å¦‚æœæŒ‡å®šäº†æ—¶é—´ï¼Œæ¯”è¾ƒæ–‡ä»¶ä¿®æ”¹æ—¶é—´
        if since_time:
            try:
                since_timestamp = datetime.fromisoformat(since_time).timestamp()
            except:
                since_timestamp = 0
            
            for root, _, files in os.walk(src_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    rel_path = os.path.relpath(file_path, src_dir)
                    # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤
                    if self._should_exclude_file(rel_path, self.exclude_patterns):
                        continue
                    if os.path.getmtime(file_path) > since_timestamp:
                        changed_files.add(rel_path)
        else:
            # å¦åˆ™æ¯”è¾ƒæ–‡ä»¶å“ˆå¸Œå€¼
            metadata_file = os.path.join(self.metadata_dir, "export_metadata.json")
            if os.path.exists(metadata_file):
                try:
                    with open(metadata_file, 'r', encoding='utf-8') as f:
                        metadata = json.load(f)
                    
                    current_hashes = self._get_file_hashes(src_dir)
                    previous_hashes = metadata.get('file_hashes', {})
                     
                    for file_path, current_hash in current_hashes.items():
                        # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤
                        if self._should_exclude_file(file_path, self.exclude_patterns):
                            continue
                        previous_hash = previous_hashes.get(file_path)
                        if previous_hash != current_hash:
                            changed_files.add(file_path)
                except:
                    # å¦‚æœæ— æ³•è¯»å–å…ƒæ•°æ®ï¼Œè¿”å›æ‰€æœ‰æ–‡ä»¶ï¼ˆæ’é™¤æ’é™¤çš„æ–‡ä»¶ï¼‰
                    for root, _, files in os.walk(src_dir):
                        for file in files:
                            file_path = os.path.join(root, file)
                            rel_path = os.path.relpath(file_path, src_dir)
                            if not self._should_exclude_file(rel_path, self.exclude_patterns):
                                changed_files.add(rel_path)
            else:
                # å¦‚æœæ²¡æœ‰å…ƒæ•°æ®ï¼Œè¿”å›æ‰€æœ‰æ–‡ä»¶ï¼ˆæ’é™¤æ’é™¤çš„æ–‡ä»¶ï¼‰
                for root, _, files in os.walk(src_dir):
                    for file in files:
                        file_path = os.path.join(root, file)
                        rel_path = os.path.relpath(file_path, src_dir)
                        if not self._should_exclude_file(rel_path, self.exclude_patterns):
                            changed_files.add(rel_path)
        
        return changed_files

    def _get_file_hashes(self, src_dir: str) -> Dict[str, str]:
        """
        è·å–ç›®å½•ä¸­æ‰€æœ‰æ–‡ä»¶çš„å“ˆå¸Œå€¼ï¼ˆæ’é™¤æŒ‡å®šçš„æ–‡ä»¶ï¼‰
        """
        file_hashes = {}
        for root, _, files in os.walk(src_dir):
            for file in files:
                file_path = os.path.join(root, file)
                rel_path = os.path.relpath(file_path, src_dir)
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤
                if self._should_exclude_file(rel_path, self.exclude_patterns):
                    continue
                try:
                    with open(file_path, 'rb') as f:
                        content = f.read()
                        file_hash = hashlib.md5(content).hexdigest()
                        file_hashes[rel_path] = file_hash
                except:
                    file_hashes[rel_path] = " "
        return file_hashes

    def _save_export_metadata_multi(self, src_dirs: List[str], output_file: str):
        """
        ä¿å­˜å¤šä¸ªç›®å½•çš„å¯¼å‡ºå…ƒæ•°æ®ï¼Œç”¨äºå¢é‡å¯¼å‡º
        """
        if not os.path.exists(self.metadata_dir):
            os.makedirs(self.metadata_dir)
        
        all_file_hashes = {}
        for src_dir in src_dirs:
            dir_hashes = self._get_file_hashes(src_dir)
            all_file_hashes.update(dir_hashes)
            
        metadata = {
            'export_time': datetime.now().isoformat(),
            'source_dirs': [os.path.abspath(src_dir) for src_dir in src_dirs],
            'output_file': os.path.abspath(output_file),
            'file_hashes': all_file_hashes
        }
         
        metadata_file = os.path.join(self.metadata_dir, "export_metadata.json")
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)

    def _calculate_diff(self, file_path: str, new_content: str) -> Dict:
        """
        è®¡ç®—æ–‡ä»¶å·®å¼‚ï¼ˆæ›´è¯¦ç»†çš„å®ç°ï¼‰
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                old_content = f.read()
        except:
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— æ³•è¯»å–ï¼Œè®¤ä¸ºæ˜¯æ–°å¢æ–‡ä»¶
            return {
                'type': 'new_file',
                'summary': 'æ–°å¢æ–‡ä»¶',
                'lines_added': len(new_content.split('\n')),
                'lines_removed': 0,
                'lines_modified': 0
            }
        
        old_lines = old_content.split('\n')
        new_lines = new_content.split('\n')
        
        # æ£€æŸ¥å†…å®¹æ˜¯å¦å®Œå…¨ç›¸åŒ
        if old_content == new_content:
            return {
                'type': 'no_change',
                'summary': 'æ— å˜åŒ–',
                'lines_added': 0,
                'lines_removed': 0,
                'lines_modified': 0
            }
        
        # è®¡ç®—åŸºæœ¬å·®å¼‚ç»Ÿè®¡
        old_line_count = len(old_lines)
        new_line_count = len(new_lines)
         
        lines_added = max(0, new_line_count - old_line_count)
        lines_removed = max(0, old_line_count - new_line_count)
        
        # ç®€å•çš„å·®å¼‚æè¿°
        if lines_added > 0 and lines_removed > 0:
            summary = f'ä¿®æ”¹æ–‡ä»¶ (æ–°å¢{lines_added}è¡Œ, åˆ é™¤{lines_removed}è¡Œ)'
        elif lines_added > 0:
            summary = f'ä¿®æ”¹æ–‡ä»¶ (æ–°å¢{lines_added}è¡Œ)'
        elif lines_removed > 0:
            summary = f'ä¿®æ”¹æ–‡ä»¶ (åˆ é™¤{lines_removed}è¡Œ)'
        else:
            summary = 'ä¿®æ”¹æ–‡ä»¶å†…å®¹'
        
        return {
            'type': 'modified',
            'summary': summary,
            'lines_added': lines_added,
            'lines_removed': lines_removed,
            'lines_modified': 0
        }

    def _get_language_by_extension(self, filename: str) -> str:
        """æ ¹æ®æ–‡ä»¶æ‰©å±•åè·å–ç¼–ç¨‹è¯­è¨€"""
        _, ext = os.path.splitext(filename.lower())
        return self.language_map.get(ext, 'text')

    def validate_response_format(self, markdown_content: str, verbose: bool = False) -> Dict:
        """
        éªŒè¯AIå“åº”æ ¼å¼æ˜¯å¦æ­£ç¡®
        """
        return self.response_validator.validate(markdown_content, verbose)

    def list_supported_extensions(self) -> List[str]:
        """åˆ—å‡ºæ”¯æŒçš„æ–‡ä»¶æ‰©å±•å"""
        return sorted(list(set(self.language_map.keys())))

    def debug_parse_response(self, markdown_file: str):
        """
        è°ƒè¯•æ–¹æ³•ï¼šæ˜¾ç¤ºè§£æç»“æœ
        """
        try:
            with open(markdown_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            print("=== æ ‡å‡†è§£æç»“æœ ===")
            standard_files = self.response_parser.extract_files_standard(content)
            for i, (file_path, lang, file_content) in enumerate(standard_files):
                print(f"æ–‡ä»¶ {i+1}: {file_path} ({lang})")
                print(f"å†…å®¹é•¿åº¦: {len(file_content)} å­—ç¬¦")
                print("---")
            
            print(f"\næ€»å…±è¯†åˆ«åˆ° {len(standard_files)} ä¸ªæ–‡ä»¶")
            
            if not standard_files:
                print("\n=== çµæ´»è§£æç»“æœ ===")
                flexible_files = self.response_parser.extract_files_flexible(content)
                for i, (file_path, lang, file_content) in enumerate(flexible_files):
                    print(f"æ–‡ä»¶ {i+1}: {file_path} ({lang})")
                    print(f"å†…å®¹é•¿åº¦: {len(file_content)} å­—ç¬¦")
                    print("---")
                print(f"æ€»å…±è¯†åˆ«åˆ° {len(flexible_files)} ä¸ªæ–‡ä»¶")
                
        except Exception as e:
            print(f"è°ƒè¯•è§£æå¤±è´¥: {e}")

    def init_config(self):
        """åˆå§‹åŒ–é…ç½®æ–‡ä»¶"""
        self.config_manager.init_config_file()

    def show_config(self):
        """æ˜¾ç¤ºå½“å‰é…ç½®"""
        self.config_manager.show_config()

    def debug_parse_detailed(self, markdown_file: str):
        """
        è¯¦ç»†è°ƒè¯•è§£æï¼šæ˜¾ç¤ºè§£æè¿‡ç¨‹ä¸­çš„æ¯ä¸€æ­¥
        """
        try:
            with open(markdown_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            print("=== è¯¦ç»†è§£æè°ƒè¯• ===")
            print("åŸå§‹å†…å®¹è¡Œæ•°: ", len(content.split('\n')))
            
            # å°è¯•æ ‡å‡†è§£æ
            print("\n--- æ ‡å‡†è§£æå°è¯• ---")
            standard_files = self.response_parser.extract_files_standard(content)
            print(f"æ ‡å‡†è§£ææ‰¾åˆ° {len(standard_files)} ä¸ªæ–‡ä»¶")
            
            for i, (file_path, lang, file_content) in enumerate(standard_files):
                print(f"  æ–‡ä»¶ {i+1}: {file_path}")
                print(f"  è¯­è¨€: {lang}")
                print(f"  å†…å®¹è¡Œæ•°: {len(file_content.split())}")
                print("  å†…å®¹é¢„è§ˆ: ")
                lines = file_content.split('\n')[:5]
                for line in lines:
                    print(f"    {line}")
                print()
            
            # å¦‚æœæ ‡å‡†è§£æå¤±è´¥ï¼Œå°è¯•çµæ´»è§£æ
            if not standard_files:
                print("\n--- çµæ´»è§£æå°è¯• ---")
                flexible_files = self.response_parser.extract_files_flexible(content)
                print(f"çµæ´»è§£ææ‰¾åˆ° {len(flexible_files)} ä¸ªæ–‡ä»¶")
                
                for i, (file_path, lang, file_content) in enumerate(flexible_files):
                    print(f"  æ–‡ä»¶ {i+1}: {file_path}")
                    print(f"  è¯­è¨€: {lang}")
                    print(f"  å†…å®¹è¡Œæ•°: {len(file_content.split())}")
                    print("  å†…å®¹é¢„è§ˆ: ")
                    lines = file_content.split('\n')[:5]
                    for line in lines:
                        print(f"    {line}")
                    print()
            
            # æ˜¾ç¤ºæ–‡ä»¶æ ‡é¢˜è¡Œ
            print("\n--- æ‰€æœ‰ ## å¼€å¤´çš„è¡Œ ---")
            lines = content.split('\n')
            for i, line in enumerate(lines):
                if line.strip().startswith('##'):
                    print(f"  è¡Œ {i+1}: {line.strip()}")
                    
        except Exception as e:
            print(f"è°ƒè¯•è§£æå¤±è´¥: {e}")